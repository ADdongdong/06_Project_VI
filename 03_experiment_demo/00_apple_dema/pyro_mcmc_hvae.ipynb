{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "module has no parameters",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 135\u001b[0m\n\u001b[1;32m    132\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m100\u001b[39m, input_dim)\n\u001b[1;32m    134\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m model\u001b[39m.\u001b[39;49mfit(x, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[9], line 119\u001b[0m, in \u001b[0;36mHVAE.fit\u001b[0;34m(self, x, num_epochs)\u001b[0m\n\u001b[1;32m    117\u001b[0m pyro\u001b[39m.\u001b[39mclear_param_store()\n\u001b[1;32m    118\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m--> 119\u001b[0m     loss \u001b[39m=\u001b[39m svi\u001b[39m.\u001b[39;49mstep(x)\n\u001b[1;32m    120\u001b[0m     \u001b[39m#loss = svi.step({\"obs\":x})\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39mwith\u001b[39;00m poutine\u001b[39m.\u001b[39mtrace(param_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_and_grads(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mguide, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    147\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munconstrained() \u001b[39mfor\u001b[39;00m site \u001b[39min\u001b[39;00m param_capture\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39mnodes\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[39m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/pyro/infer/trace_elbo.py:140\u001b[0m, in \u001b[0;36mTrace_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m    139\u001b[0m \u001b[39m# grab a trace from the generator\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[39mfor\u001b[39;00m model_trace, guide_trace \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_traces(model, guide, args, kwargs):\n\u001b[1;32m    141\u001b[0m     loss_particle, surrogate_loss_particle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_differentiable_loss_particle(\n\u001b[1;32m    142\u001b[0m         model_trace, guide_trace\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_particle \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_particles\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/pyro/infer/elbo.py:236\u001b[0m, in \u001b[0;36mELBO._get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_particles):\n\u001b[0;32m--> 236\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_trace(model, guide, args, kwargs)\n",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m, in \u001b[0;36mCustomELBO._get_trace\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_trace\u001b[39m(\u001b[39mself\u001b[39m, model, guide, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m----> 9\u001b[0m     trace \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_get_trace(model, guide, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     11\u001b[0m     \u001b[39m# Access the sampled latent variables from the trace\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     z_1 \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39mnodes[\u001b[39m\"\u001b[39m\u001b[39mz1\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/pyro/infer/trace_elbo.py:57\u001b[0m, in \u001b[0;36mTrace_ELBO._get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_trace\u001b[39m(\u001b[39mself\u001b[39m, model, guide, args, kwargs):\n\u001b[1;32m     53\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m    Returns a single trace from the guide, and the model that is run\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m    against it.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     model_trace, guide_trace \u001b[39m=\u001b[39m get_importance_trace(\n\u001b[1;32m     58\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mflat\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_plate_nesting, model, guide, args, kwargs\n\u001b[1;32m     59\u001b[0m     )\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     61\u001b[0m         check_if_enumerated(guide_trace)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/pyro/infer/enum.py:65\u001b[0m, in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m detach:\n\u001b[1;32m     64\u001b[0m         guide_trace\u001b[39m.\u001b[39mdetach_()\n\u001b[0;32m---> 65\u001b[0m     model_trace \u001b[39m=\u001b[39m poutine\u001b[39m.\u001b[39;49mtrace(\n\u001b[1;32m     66\u001b[0m         poutine\u001b[39m.\u001b[39;49mreplay(model, trace\u001b[39m=\u001b[39;49mguide_trace), graph_type\u001b[39m=\u001b[39;49mgraph_type\n\u001b[1;32m     67\u001b[0m     )\u001b[39m.\u001b[39;49mget_trace(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     70\u001b[0m     check_model_guide_match(model_trace, guide_trace, max_plate_nesting)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/pyro/poutine/trace_messenger.py:198\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_trace\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    191\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39m    :returns: data structure\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[39m    :rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m    Calls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd_node(\n\u001b[1;32m    171\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    176\u001b[0m     exc_type, exc_value, traceback \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_context_wrap\u001b[39m(context, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn[9], line 79\u001b[0m, in \u001b[0;36mHVAE.model\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 79\u001b[0m     pyro\u001b[39m.\u001b[39;49mmodule(\u001b[39m\"\u001b[39;49m\u001b[39mhvae\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m)\n\u001b[1;32m     81\u001b[0m     \u001b[39mwith\u001b[39;00m pyro\u001b[39m.\u001b[39mplate(\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m, x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[1;32m     82\u001b[0m         \u001b[39m# First encoding\u001b[39;00m\n\u001b[1;32m     83\u001b[0m         z1_loc, z1_scale \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder1(x)\u001b[39m.\u001b[39mchunk(\u001b[39m2\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/pyro/primitives.py:420\u001b[0m, in \u001b[0;36mmodule\u001b[0;34m(name, nn_module, update_module_params)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodule\u001b[39m(name, nn_module, update_module_params\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    396\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[39m    Registers all parameters of a :class:`torch.nn.Module` with Pyro's\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[39m    :mod:`~pyro.params.param_store`.  In conjunction with the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39m    :returns: torch.nn.Module\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 420\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mhasattr\u001b[39m(nn_module, \u001b[39m\"\u001b[39m\u001b[39mparameters\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mmodule has no parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    421\u001b[0m     \u001b[39massert\u001b[39;00m _MODULE_NAMESPACE_DIVIDER \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m name, (\n\u001b[1;32m    422\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mimproper module name, since contains \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m _MODULE_NAMESPACE_DIVIDER\n\u001b[1;32m    423\u001b[0m     )\n\u001b[1;32m    425\u001b[0m     \u001b[39mif\u001b[39;00m isclass(nn_module):\n",
      "\u001b[0;31mAssertionError\u001b[0m: module has no parameters"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "class CustomELBO(Trace_ELBO):\n",
    "    def _get_trace(self, model, guide, *args, **kwargs):\n",
    "        trace = super()._get_trace(model, guide, *args, **kwargs)\n",
    "\n",
    "        # Access the sampled latent variables from the trace\n",
    "        z_1 = trace.nodes[\"z1\"][\"value\"]\n",
    "        z_2 = trace.nodes[\"z2\"][\"value\"]\n",
    "\n",
    "        # Get the reconstructed images\n",
    "        loc_x1 = model.decoder1(z_2)\n",
    "        loc_x2 = model.decoder2(z_1)\n",
    "\n",
    "        # Compute the reconstruction loss\n",
    "        x = kwargs[\"obs\"]\n",
    "        recon_loss = -dist.Normal(loc_x1, 1.0).log_prob(x).sum(-1)\n",
    "        recon_loss += -dist.Normal(loc_x2, 1.0).log_prob(x).sum(-1)\n",
    "\n",
    "        # Compute the KL divergence\n",
    "        kl_divergence = 0.5 * (z_1 ** 2).sum(-1) - 0.5 * (z_2 ** 2).sum(-1)\n",
    "\n",
    "        # Compute the ELBO\n",
    "        elbo = recon_loss - kl_divergence\n",
    "\n",
    "        # Update the trace with the ELBO value\n",
    "        trace.add_node(\"elbo\", value=elbo.sum())\n",
    "\n",
    "        return trace\n",
    "\n",
    "\n",
    "class HVAE:\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, latent_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # 注册模型的参数\n",
    "        # 注册模型的参数\n",
    "        self.z1_loc = pyro.param(\"z1_loc\", torch.zeros(latent_dim))\n",
    "        self.z1_scale = pyro.param(\"z1_scale\", torch.ones(latent_dim))\n",
    "        self.z2_loc = pyro.param(\"z2_loc\", torch.zeros(latent_dim))\n",
    "        self.z2_scale = pyro.param(\"z2_scale\", torch.ones(latent_dim))\n",
    "\n",
    "        # Define encoder1\n",
    "        self.encoder1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_dim1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim1, latent_dim * 2)\n",
    "        )\n",
    "\n",
    "        # Define encoder2\n",
    "        self.encoder2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim, hidden_dim2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim2, latent_dim * 2)\n",
    "        )\n",
    "\n",
    "        # Define decoder1\n",
    "        self.decoder1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim, hidden_dim2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim2, input_dim)\n",
    "        )\n",
    "\n",
    "        # Define decoder2\n",
    "        self.decoder2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim, hidden_dim1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim1, input_dim)\n",
    "        )\n",
    "\n",
    "    def model(self, x):\n",
    "        pyro.module(\"hvae\", self)\n",
    "\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # First encoding\n",
    "            z1_loc, z1_scale = self.encoder1(x).chunk(2, dim=-1)\n",
    "            z1 = pyro.sample(\"z1\", dist.Normal(z1_loc, z1_scale).to_event(1))\n",
    "\n",
    "            # Second encoding\n",
    "            z2_loc, z2_scale = self.encoder2(z1).chunk(2, dim=-1)\n",
    "            z2 = pyro.sample(\"z2\", dist.Normal(z2_loc, z2_scale).to_event(1))\n",
    "\n",
    "            # First decoding\n",
    "            loc_x1 = self.decoder1(z2)\n",
    "            pyro.sample(\"obs1\", dist.Normal(loc_x1, 1.0).to_event(1), obs=x)\n",
    "\n",
    "            # Second decoding\n",
    "            loc_x2 = self.decoder2(z1)\n",
    "            pyro.sample(\"obs2\", dist.Normal(loc_x2, 1.0).to_event(1), obs=x)\n",
    "\n",
    "    def guide(self, x):\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # First encoding parameters\n",
    "            z1_loc = pyro.param(\"z1_loc\", torch.zeros(x.shape[0], self.latent_dim))\n",
    "            z1_scale = pyro.param(\"z1_scale\", torch.ones(x.shape[0], self.latent_dim))\n",
    "            z1 = pyro.sample(\"z1\", dist.Normal(z1_loc, z1_scale).to_event(1))\n",
    "\n",
    "            # Second encoding parameters\n",
    "            z2_loc = pyro.param(\"z2_loc\", torch.zeros(x.shape[0], self.latent_dim))\n",
    "            z2_scale = pyro.param(\"z2_scale\", torch.ones(x.shape[0], self.latent_dim))\n",
    "            z2 = pyro.sample(\"z2\", dist.Normal(z2_loc, z2_scale).to_event(1))\n",
    "\n",
    "            return z1, z2\n",
    "\n",
    "    def fit(self, x, num_epochs):\n",
    "        optimizer = Adam({\"lr\": 0.01})\n",
    "        elbo = CustomELBO()\n",
    "        svi = SVI(self.model, self.guide, optimizer, loss=elbo)\n",
    "\n",
    "        pyro.clear_param_store()\n",
    "        for epoch in range(num_epochs):\n",
    "            loss = svi.step(x)\n",
    "            #loss = svi.step({\"obs\":x})\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss}\")\n",
    "\n",
    "# Create model instance\n",
    "input_dim = 1000\n",
    "hidden_dim1 = 256\n",
    "hidden_dim2 = 128\n",
    "latent_dim = 20\n",
    "\n",
    "model = HVAE(input_dim, hidden_dim1, hidden_dim2, latent_dim)\n",
    "\n",
    "# Generate sample data\n",
    "x = torch.randn(100, input_dim)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x, num_epochs=100)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0 (default, Nov 15 2020, 08:30:55) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "240bc028caeb8b02ff80d8aedfc61caf7a0e4db2770780d40c5b717508bae340"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
