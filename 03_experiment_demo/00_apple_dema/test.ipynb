{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Hamiltonian(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Hamiltonian, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.position = nn.Parameter(torch.randn(dim))\n",
    "        self.momentum = nn.Parameter(torch.randn(dim))\n",
    "\n",
    "    def forward(self, timesteps, step_size):\n",
    "        # Define the Hamiltonian dynamics using leapfrog integrator\n",
    "        for i in range(timesteps):\n",
    "            # Update momentum\n",
    "            self.momentum -= 0.5 * step_size * self.grad_potential(self.position)\n",
    "            # Update position\n",
    "            self.position += step_size * self.momentum\n",
    "            # Update momentum again\n",
    "            self.momentum -= 0.5 * step_size * self.grad_potential(self.position)\n",
    "\n",
    "    def grad_potential(self, x):\n",
    "        # Define the gradient of the potential energy function here\n",
    "        return torch.autograd.grad(self.potential(x), x)[0]\n",
    "\n",
    "    def potential(self, x):\n",
    "        # Define the potential energy function here\n",
    "        return torch.sum(x ** 2) / 2\n",
    "\n",
    "# Example usage:\n",
    "hamiltonian = Hamiltonian(10)\n",
    "hamiltonian.forward(100, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_elbo(model, x, num_samples=10):\n",
    "    \"\"\"\n",
    "    计算未校正的哈密顿动力学模型下的ELBO\n",
    "    \n",
    "    参数：\n",
    "        model: 未校正的哈密顿动力学模型\n",
    "        x: 输入数据，大小为[batch_size, input_size]\n",
    "        num_samples: 采样数量\n",
    "    \n",
    "    返回：\n",
    "        elbo: ELBO（Evidence Lower Bound）\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size, input_size = x.size()\n",
    "\n",
    "    # 从后验分布q(z|x)中采样num_samples个样本\n",
    "    z_samples = []\n",
    "    for i in range(num_samples):\n",
    "        z_q, _ = model.q_z(x)\n",
    "        z_samples.append(z_q)\n",
    "\n",
    "    # 将样本堆叠成张量\n",
    "    z_samples = torch.stack(z_samples)\n",
    "\n",
    "    # 计算解码器p(x|z)的对数似然\n",
    "    x_logits = model.p_x(z_samples).view(num_samples, batch_size, -1)\n",
    "    log_likelihood = F.log_softmax(x_logits, dim=-1).sum(-1).mean(0)\n",
    "\n",
    "    # 计算后验分布q(z|x)与先验分布p(z)之间的KL散度\n",
    "    z_p = model.sample_prior(num_samples)\n",
    "    kl_divergence = torch.distributions.kl_divergence(\n",
    "        torch.distributions.Normal(z_samples.mean(0), z_samples.std(0)),\n",
    "        torch.distributions.Normal(z_p, torch.ones_like(z_p))\n",
    "    ).sum(-1).mean(0)\n",
    "\n",
    "    # 计算ELBO\n",
    "    elbo = log_likelihood - kl_divergence\n",
    "\n",
    "    return -elbo  # 返回负数，因为我们使用优化器最小化损失函数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Mar  8 2023, 14:00:05) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c76da3b56f7b51de8598cd3a1b1952e7a7c2b08e80c4d8d0dcb567dfaa788a0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
