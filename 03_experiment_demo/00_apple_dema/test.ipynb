{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_elbo(model, x, num_samples=10):\n",
    "    \"\"\"\n",
    "    计算未校正的哈密顿动力学模型下的ELBO\n",
    "    \n",
    "    参数：\n",
    "        model: 未校正的哈密顿动力学模型\n",
    "        x: 输入数据，大小为[batch_size, input_size]\n",
    "        num_samples: 采样数量\n",
    "    \n",
    "    返回：\n",
    "        elbo: ELBO（Evidence Lower Bound）\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size, input_size = x.size()\n",
    "\n",
    "    # 从后验分布q(z|x)中采样num_samples个样本\n",
    "    z_samples = []\n",
    "    for i in range(num_samples):\n",
    "        z_q, _ = model.q_z(x)\n",
    "        z_samples.append(z_q)\n",
    "\n",
    "    # 将样本堆叠成张量\n",
    "    z_samples = torch.stack(z_samples)\n",
    "\n",
    "    # 计算解码器p(x|z)的对数似然\n",
    "    x_logits = model.p_x(z_samples).view(num_samples, batch_size, -1)\n",
    "    log_likelihood = F.log_softmax(x_logits, dim=-1).sum(-1).mean(0)\n",
    "\n",
    "    # 计算后验分布q(z|x)与先验分布p(z)之间的KL散度\n",
    "    z_p = model.sample_prior(num_samples)\n",
    "    kl_divergence = torch.distributions.kl_divergence(\n",
    "        torch.distributions.Normal(z_samples.mean(0), z_samples.std(0)),\n",
    "        torch.distributions.Normal(z_p, torch.ones_like(z_p))\n",
    "    ).sum(-1).mean(0)\n",
    "\n",
    "    # 计算ELBO\n",
    "    elbo = log_likelihood - kl_divergence\n",
    "\n",
    "    return -elbo  # 返回负数，因为我们使用优化器最小化损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-1.6549392, -0.7325643], dtype=float32), array([-0.9294475, -0.6207985], dtype=float32), array([-1.3915583,  1.9626707], dtype=float32), array([ 0.25071254, -0.6399836 ], dtype=float32), array([-0.07853568, -1.9527625 ], dtype=float32), array([-0.7784954,  1.0815153], dtype=float32), array([-0.31023294,  0.45576578], dtype=float32), array([1.3170817 , 0.06579784], dtype=float32), array([ 0.9772804, -0.0321852], dtype=float32), array([ 0.68810326, -0.62953514], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from jax import grad\n",
    "\n",
    "class UHA:\n",
    "    '''\n",
    "    这段代码实现了HMC和UHA的步骤。HMC是一种基于哈密顿动力学的MCMC方法，\n",
    "    它通过在动量空间中进行随机游走来探索目标分布。\n",
    "    在每个时间步长内，它使用梯度信息来更新动量和位置变量。\n",
    "    具体而言，它首先对动量进行半个时间步长的更新，然后对位置进行一个完整的时间步长的更新，\n",
    "    最后再对动量进行半个时间步长的更新。\n",
    "\n",
    "    UHA是一种基于未校正哈密顿动力学的MCMC方法，它与HMC类似，但使用未校正哈密顿动力学方程来生成样本。\n",
    "    在UHA中，我们从标准正态分布中抽取一个随机初始状态，并使用未校正哈密顿动力学方程进行L_m次采样。\n",
    "    每次采样都会生成一个新状态，并将其用于计算ELBO下界。\n",
    "    '''\n",
    "    def __init__(self, dim, L_m=10, eps_m=0.1):\n",
    "        self.dim = dim\n",
    "        self.L_m = L_m\n",
    "        self.eps_m = eps_m\n",
    "\n",
    "    #定义能量函数E\n",
    "    def E(self, x):\n",
    "        return torch.sum(x ** 2) / 2\n",
    "\n",
    "    #定义能量函数的梯度\n",
    "    def grad_E(self, x):\n",
    "        E = self.E(x)\n",
    "        # dE/dx\n",
    "        return torch.autograd.grad(E, x)[0]\n",
    "\n",
    "    #HMC步骤\n",
    "    def HMC_step(self, x, p, eps):\n",
    "        # 按照哈密顿动力学仿鲿进行一半时间不长的动量更新\n",
    "        p = p - eps * self.grad_E(x) / 2\n",
    "        # 按照哈密顿动力学仿鲿进行一整个时间步长的坐标更新\n",
    "        x = x + eps * p\n",
    "        # 按照哈密顿动力学方程进行一班时间步长的动量更新\n",
    "        p = p - eps * self.grad_E(x) / 2\n",
    "        return x, p\n",
    "    \n",
    "    #UHA步骤，未校正哈密顿\n",
    "    def UHA_step(self, x):\n",
    "        #从标准正态分布中抽样\n",
    "        p = torch.randn_like(x)\n",
    "        for i in range(self.L_m):\n",
    "            #使用HMC步骤进行L_m次采样，并更新x和p\n",
    "            x, p = self.HMC_step(x, p, self.eps_m)\n",
    "        return x\n",
    "\n",
    "    #采样函数\n",
    "    def sample(self, num_samples=1):\n",
    "        samples = []\n",
    "        for i in range(num_samples):\n",
    "            # 初始化当前状态\n",
    "            x = torch.randn(self.dim).requires_grad_(True)\n",
    "\n",
    "            # 运行未校正哈密顿算法\n",
    "            for m in range(1000):\n",
    "                # 从未校正的状态转移矩阵中采样(从转移核中采样)\n",
    "                y = self.UHA_step(x)\n",
    "\n",
    "            # 保存在理目标分布的最终样本(在UHA中没有使用)\n",
    "            samples.append(y.detach().numpy())\n",
    "        return samples\n",
    "\n",
    "    #定义函数从q(z|x)中采样\n",
    "    def q_z(self, x:list, func)->list:\n",
    "        '''\n",
    "            参数x: 要采样的样本个数\n",
    "            参数func: 对那个分布(函数)进行采样\n",
    "            返回值：采样成功以后的样本列表\n",
    "        '''\n",
    "        mu, logvar = encoder(x)\n",
    "        #传入进来的是空列表\n",
    "        sample = self.sample(x)\n",
    "        return sample\n",
    "\n",
    "    #定义函数丛p(z|x)中采样\n",
    "    def p_z(x:list)->list:\n",
    "        '''\n",
    "            函数返回值为采样的列表\n",
    "        '''\n",
    "\n",
    "uha = UHA(2)\n",
    "sample = uha.sample(10)\n",
    "print(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c76da3b56f7b51de8598cd3a1b1952e7a7c2b08e80c4d8d0dcb567dfaa788a0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
